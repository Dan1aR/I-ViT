{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39959162",
   "metadata": {},
   "source": [
    "# Разбираемся в int-only инференсе для mobilenet-а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ac8446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan1ar/I-ViT/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dan1ar/I-ViT/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_QuantizedWeights.IMAGENET1K_QNNPACK_V1`. You can also use `weights=MobileNet_V3_Large_QuantizedWeights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/dan1ar/I-ViT/.venv/lib/python3.10/site-packages/torch/ao/quantization/utils.py:408: UserWarning: must run observer before calling calculate_qparams. Returning default values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizableMobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): QuantizedConv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), scale=0.5188275575637817, zero_point=123, padding=(1, 1))\n",
       "      (1): Identity()\n",
       "      (2): QuantizedHardswish()\n",
       "    )\n",
       "    (1): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConvReLU2d(16, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.05623207986354828, zero_point=0, padding=(1, 1), groups=16)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), scale=0.2755914330482483, zero_point=149)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=0.2736288607120514, zero_point=65\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConvReLU2d(16, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.07378090918064117, zero_point=0)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(2, 2), scale=0.05488698184490204, zero_point=0, padding=(1, 1), groups=64)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), scale=0.07989856600761414, zero_point=140)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConvReLU2d(24, 72, kernel_size=(1, 1), stride=(1, 1), scale=0.021039636805653572, zero_point=0)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConvReLU2d(72, 72, kernel_size=(3, 3), stride=(1, 1), scale=0.03794265538454056, zero_point=0, padding=(1, 1), groups=72)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), scale=0.10586553812026978, zero_point=127)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=0.10956046730279922, zero_point=132\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConvReLU2d(24, 72, kernel_size=(1, 1), stride=(1, 1), scale=0.029090378433465958, zero_point=0)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConvReLU2d(72, 72, kernel_size=(5, 5), stride=(2, 2), scale=0.025117257609963417, zero_point=0, padding=(2, 2), groups=72)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (2): QuantizableSqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): QuantizedConvReLU2d(72, 24, kernel_size=(1, 1), stride=(1, 1), scale=0.02236168645322323, zero_point=0)\n",
       "          (fc2): QuantizedConv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), scale=0.012691566720604897, zero_point=0)\n",
       "          (activation): Identity()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "          (skip_mul): QFunctional(\n",
       "            scale=0.024224359542131424, zero_point=0\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), scale=0.07847321033477783, zero_point=145)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConvReLU2d(40, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.01254982315003872, zero_point=0)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConvReLU2d(120, 120, kernel_size=(5, 5), stride=(1, 1), scale=0.055628854781389236, zero_point=0, padding=(2, 2), groups=120)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (2): QuantizableSqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): QuantizedConvReLU2d(120, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.014458825811743736, zero_point=0)\n",
       "          (fc2): QuantizedConv2d(32, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.04251876100897789, zero_point=160)\n",
       "          (activation): Identity()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "          (skip_mul): QFunctional(\n",
       "            scale=0.016700848937034607, zero_point=0\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), scale=0.05273246765136719, zero_point=136)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=0.06936204433441162, zero_point=134\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConvReLU2d(40, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.01267621573060751, zero_point=0)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConvReLU2d(120, 120, kernel_size=(5, 5), stride=(1, 1), scale=0.06592829525470734, zero_point=0, padding=(2, 2), groups=120)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (2): QuantizableSqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): QuantizedConvReLU2d(120, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.013499085791409016, zero_point=0)\n",
       "          (fc2): QuantizedConv2d(32, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.03198779374361038, zero_point=122)\n",
       "          (activation): Identity()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "          (skip_mul): QFunctional(\n",
       "            scale=0.035042185336351395, zero_point=0\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), scale=0.06589071452617645, zero_point=133)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=0.100160151720047, zero_point=135\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (7): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), scale=0.07622719556093216, zero_point=128)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), scale=0.09642932564020157, zero_point=155, padding=(1, 1), groups=240)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), scale=0.04727643355727196, zero_point=133)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (8): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), scale=0.03380287066102028, zero_point=162)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), scale=0.034818798303604126, zero_point=168, padding=(1, 1), groups=200)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), scale=0.04413709044456482, zero_point=108)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=0.0480157807469368, zero_point=127\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (9): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), scale=0.04212459549307823, zero_point=142)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), scale=0.03184368833899498, zero_point=169, padding=(1, 1), groups=184)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), scale=0.055781155824661255, zero_point=112)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=0.07629841566085815, zero_point=112\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (10): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), scale=0.08524257689714432, zero_point=125)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), scale=0.0474659726023674, zero_point=148, padding=(1, 1), groups=184)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), scale=0.058571573346853256, zero_point=142)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=0.0540243498980999, zero_point=124\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (11): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), scale=0.06307634711265564, zero_point=132)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), scale=0.135407954454422, zero_point=105, padding=(1, 1), groups=480)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (2): QuantizableSqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): QuantizedConvReLU2d(480, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.013606092892587185, zero_point=0)\n",
       "          (fc2): QuantizedConv2d(120, 480, kernel_size=(1, 1), stride=(1, 1), scale=0.033570922911167145, zero_point=141)\n",
       "          (activation): Identity()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "          (skip_mul): QFunctional(\n",
       "            scale=0.01759321056306362, zero_point=22\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), scale=0.03639154136180878, zero_point=126)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (12): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), scale=0.05390532314777374, zero_point=134)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), scale=0.15024931728839874, zero_point=82, padding=(1, 1), groups=672)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (2): QuantizableSqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): QuantizedConvReLU2d(672, 168, kernel_size=(1, 1), stride=(1, 1), scale=0.010838265530765057, zero_point=0)\n",
       "          (fc2): QuantizedConv2d(168, 672, kernel_size=(1, 1), stride=(1, 1), scale=0.0467037633061409, zero_point=182)\n",
       "          (activation): Identity()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "          (skip_mul): QFunctional(\n",
       "            scale=0.014563270844519138, zero_point=27\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), scale=0.03741815686225891, zero_point=133)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=0.048243436962366104, zero_point=126\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (13): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), scale=0.0686936229467392, zero_point=111)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), scale=0.08852090686559677, zero_point=97, padding=(2, 2), groups=672)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (2): QuantizableSqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): QuantizedConvReLU2d(672, 168, kernel_size=(1, 1), stride=(1, 1), scale=0.013169599696993828, zero_point=0)\n",
       "          (fc2): QuantizedConv2d(168, 672, kernel_size=(1, 1), stride=(1, 1), scale=0.030061228200793266, zero_point=150)\n",
       "          (activation): Identity()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "          (skip_mul): QFunctional(\n",
       "            scale=0.012502697296440601, zero_point=29\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), scale=0.03140930458903313, zero_point=133)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (14): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), scale=0.06231524795293808, zero_point=106)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), scale=0.107247494161129, zero_point=98, padding=(2, 2), groups=960)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (2): QuantizableSqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): QuantizedConvReLU2d(960, 240, kernel_size=(1, 1), stride=(1, 1), scale=0.014407780952751637, zero_point=0)\n",
       "          (fc2): QuantizedConv2d(240, 960, kernel_size=(1, 1), stride=(1, 1), scale=0.04064808413386345, zero_point=141)\n",
       "          (activation): Identity()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "          (skip_mul): QFunctional(\n",
       "            scale=0.019154321402311325, zero_point=20\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), scale=0.028393592685461044, zero_point=127)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=0.037061259150505066, zero_point=128\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (15): QuantizableInvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), scale=0.06087042763829231, zero_point=135)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), scale=0.10824012011289597, zero_point=93, padding=(2, 2), groups=960)\n",
       "          (1): Identity()\n",
       "          (2): QuantizedHardswish()\n",
       "        )\n",
       "        (2): QuantizableSqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): QuantizedConvReLU2d(960, 240, kernel_size=(1, 1), stride=(1, 1), scale=0.023861462250351906, zero_point=0)\n",
       "          (fc2): QuantizedConv2d(240, 960, kernel_size=(1, 1), stride=(1, 1), scale=0.048545725643634796, zero_point=130)\n",
       "          (activation): Identity()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "          (skip_mul): QFunctional(\n",
       "            scale=0.035266902297735214, zero_point=11\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): QuantizedConv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), scale=0.07612480968236923, zero_point=126)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): QFunctional(\n",
       "        scale=0.08560287207365036, zero_point=127\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (16): Conv2dNormActivation(\n",
       "      (0): QuantizedConv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), scale=0.25198760628700256, zero_point=104)\n",
       "      (1): Identity()\n",
       "      (2): QuantizedHardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): QuantizedLinear(in_features=960, out_features=1280, scale=0.06315616518259048, zero_point=155, qscheme=torch.per_tensor_affine)\n",
       "    (1): QuantizedHardswish()\n",
       "    (2): QuantizedDropout(p=0.2, inplace=True)\n",
       "    (3): QuantizedLinear(in_features=1280, out_features=1000, scale=0.18467451632022858, zero_point=106, qscheme=torch.per_tensor_affine)\n",
       "  )\n",
       "  (quant): Quantize(scale=tensor([0.0187]), zero_point=tensor([114]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models.quantization as models\n",
    "\n",
    "# Load pre-trained quantized MobileNetV3-Large\n",
    "model = models.mobilenet_v3_large(pretrained=True, quantize=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9980312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
